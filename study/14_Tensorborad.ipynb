{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6575cde",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4ba993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e659730",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7777)\n",
    "tf.random.set_seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc1b4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) float32\n",
      "(50000, 10) float32\n",
      "(10000, 32, 32, 3) float32\n",
      "(10000, 10) float32\n"
     ]
    }
   ],
   "source": [
    "class Cifar10DataLoader():\n",
    "    \n",
    "    def __init__(self):\n",
    "        (self.train_x, self.train_y),(self.test_x, self.test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "        self.input_shape = self.train_x.shape[1:]\n",
    "    \n",
    "    def scale(self, x):\n",
    "        return (x / 255.0).astype(np.float32)\n",
    "    \n",
    "    def preprocess_dataset(self, dataset):\n",
    "        feature, target = dataset\n",
    "        \n",
    "        # scale\n",
    "        scaled_x = np.array([self.scale(x) for x in feature])\n",
    "    \n",
    "        # label encoding\n",
    "        ohe_y = np.array([tf.keras.utils.to_categorical(y, num_classes=10) for y in target])\n",
    "        \n",
    "        return scaled_x, ohe_y.squeeze(1)\n",
    "    \n",
    "    def get_train_dataset(self):\n",
    "        return self.preprocess_dataset((self.train_x, self.train_y))\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.preprocess_dataset((self.test_x, self.test_y))\n",
    "    \n",
    "cifar10_loader = Cifar10DataLoader()\n",
    "train_x, train_y = cifar10_loader.get_train_dataset()\n",
    "\n",
    "print(train_x.shape, train_x.dtype)\n",
    "print(train_y.shape, train_y.dtype)\n",
    "\n",
    "test_x, test_y = cifar10_loader.get_test_dataset()\n",
    "\n",
    "print(test_x.shape, test_x.dtype)\n",
    "print(test_y.shape, test_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14aba191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 32)   896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 8, 8, 32)     0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 32)     1056        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 32)     9248        ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 32)     1056        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 32)     1056        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 32)     0           ['conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 32)     1056        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 8, 8, 32)     9248        ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 32)     1056        ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 8, 8, 32)     0           ['add[0][0]',                    \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 32)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           5130        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,802\n",
      "Trainable params: 29,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Add\n",
    "\n",
    "def build_resnet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    net = Conv2D(32, kernel_size=3, strides=2, padding='same', activation='relu')(inputs)\n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1) \n",
    "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net1_1 = Conv2D(32, kernel_size=1, padding='same')(net)\n",
    "    net = Add()([net1_1, net3])\n",
    "    \n",
    "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1) \n",
    "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net = Add()([net, net3])\n",
    "    \n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    net = Dense(10, activation='softmax')(net)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=net, name ='resnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model= build_resnet((32,32,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461f349",
   "metadata": {},
   "source": [
    "### fit 함수로 학습 할 때는 callback 함수로 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937ca6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a9632fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "cur_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b520d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/fit/' + cur_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1228d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/fit/20230304-045301'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31dbb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback=tf.keras.callbacks.TensorBoard(log_dir= log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00a0102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangminju\\miniconda3\\envs\\ds_study\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 35s 21ms/step - loss: 2.3351 - accuracy: 0.0990 - val_loss: 2.3581 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 2.3415 - accuracy: 0.1016 - val_loss: 2.3160 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 2.3394 - accuracy: 0.0964 - val_loss: 2.3228 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 2.3436 - accuracy: 0.1001 - val_loss: 2.3383 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 2.3446 - accuracy: 0.1007 - val_loss: 2.3189 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2a8acad90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_x, y=train_y, epochs=5, validation_data=(test_x, test_y), callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88d9491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa1e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e55ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f809b384",
   "metadata": {},
   "source": [
    "### tf.summary 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b5f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(y, pred)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, pred)\n",
    "\n",
    "@tf.function\n",
    "def test_step(x,y):\n",
    "    \n",
    "    pred = model(x)\n",
    "    loss = loss_fn(y, pred)\n",
    "    \n",
    "    test_loss = (loss)\n",
    "    test_accuracy(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995b9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_dir = 'logs/grad_tape/train' + cur_time \n",
    "test_log_dir =  'logs/grad_tape/test' + cur_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061e7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc526e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1550\r"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "num_train_batch = train_x.shape[0] // batch_size\n",
    "num_test_batch = test_x.shape[0] // batch_size\n",
    "for epoch in range(5):\n",
    "    \n",
    "    for i in range(num_train_batch):\n",
    "        idx = i * batch_size\n",
    "        x,y = train_x[idx:idx+batch_size], train_y[idx:idx+batch_size]\n",
    "        \n",
    "        train_step(x,y)\n",
    "        print('train', i, end='\\r')\n",
    "        \n",
    "    for i in range(num_test_batch):\n",
    "        idx = i * batch_size\n",
    "        x,y = test_x[idx:idx+batch_size], test_y[idx:idx+batch_size]\n",
    "        \n",
    "        test_step(x,y)\n",
    "        print('test', i, end='\\r') \n",
    "        \n",
    "    with train_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('acc', train_accuracy.result(), step=epoch)\n",
    "        \n",
    "    with test_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('acc', test_accuracy.result(), step=epoch)\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dda9e060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/grad_tape --bind_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70140c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2b77638",
   "metadata": {},
   "source": [
    "### Tensorboard에 이미지 데이터 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92a85df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_x[777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60fc0b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b360910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsx0lEQVR4nO3dfXCV5Z3/8c99Ts45IZAHI5AQCRRQoVahs6zSjK1rhRXYGUcrvxltO7PYdXR0g7PKdtuy02p1txPXzljb/ij+sS5sZ4p23Sk6OlNcxRJ+3QJbqAzah4xQumAhQal5IA/n4b6v3x/U7EZBrm9IuJLwfs2cGZLz5cp139d9n2/unHM+J3LOOQEAcJ6lQk8AAHBhogEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIIoCz2B90uSREePHlVlZaWiKAo9HQCAkXNOPT09amhoUCp15uucMdeAjh49qsbGxtDTAACcoyNHjmjmzJlnvH/UGtD69ev1zW9+U+3t7Vq0aJG++93v6pprrjnr/6usrJQkfWPjyyqvmOz1s2JDmpAzXlQ5+Y8dG6/YSpZ5GBOTRjdhybadSTzx056SyLaNSSoZpZlI1vWxVFvOB0lSbDjKrcesaTNH968plv0ymmeD/XHC/zhMEv/afH+f/u89/2fw8fxMRqUB/fCHP9TatWv15JNPasmSJXriiSe0fPlytbW1afr06R/6f9/7s1t5xWRNqpji9fMsDSihAY0AGtD70YDOIC4aBr8wGtBorvxYaUDvOdvTKKPyIoTHH39cd911l77whS/oiiuu0JNPPqmKigr9y7/8y2j8OADAODTiDahQKGjv3r1atmzZ//yQVErLli3Tzp07P1Cfz+fV3d095AYAmPhGvAG98847iuNYdXV1Q75fV1en9vb2D9S3tLSourp68MYLEADgwhD8fUDr1q1TV1fX4O3IkSOhpwQAOA9G/EUIU6dOVTqdVkdHx5Dvd3R0qL6+/gP1uVxOuVxupKcBABjjRvwKKJvNavHixdq2bdvg95Ik0bZt29TU1DTSPw4AME6Nysuw165dq9WrV+tP//RPdc011+iJJ55Qb2+vvvCFL4zGjwMAjEOj0oBuu+02vf3223rwwQfV3t6uj3/849q6desHXpgAALhwjVoSwpo1a7RmzZph//90ukzpMs/pGd5MZY2XsyQnpI1jZw311jeBWXL0RjtzzzR143sRTW8ATEbvDbFxZFufeJTmcYp5JxoYj5V0xlZvYUlAGb1ZSDK+Gd44G8set57LljeuWh6DXMnvDcjBXwUHALgw0YAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQdCAAABBjFoUz7nKZU7dfCSGvJx4FKN4osgaseEfyGL9rPdRjeKxJr240fs9xxkWyLoPLfUl406x1lvKnSGa6lS9IY7FPG1TkIxtcNNxO7phPCnD8OYYJtNxazzGDfWWx7e0Zy1XQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgxmwWXGUuUkXOL+upZMhKio1ZSckoZsFZur8tU8smMudH2bjEkE1mHdywW4xRcKaMtNiYpxcrbapPTJO3/V5pWZ9SbNuJsWEu1mPcGmFoY11P/30YWzMJDQF89rxD/3knhnnEab915woIABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABDEmI3iqcommpzzi4kouth73JIhekKSnCGRwzay7LEz45QliWc02WNKRjOKx1ZvSEFRZJyL5ZQopmz7sOD8I4fMETWG+si4v5315DTsc2Nil5zpPxhjmAwPcInhRI7TfuNyBQQACIIGBAAIggYEAAiCBgQACIIGBAAIggYEAAiCBgQACIIGBAAIggYEAAiCBgQACIIGBAAIYsxmwaXiXqVKfnlCFRn/zUhskVCKDZlQSWTr54mp/4+l4Dhr1ph//WhupSX3SpKcJfvKmgVnPVYMc7HmmCWmrDFjXpvhGE9ZAu9k2yeWWskU7WbmjHmUMmTepVLWzDt/ln3iGQXHFRAAIIwRb0Bf//rXFUXRkNuCBQtG+scAAMa5UfkT3Mc+9jG98sor//NDysbsX/oAAIGMSmcoKytTfX39aAwNAJggRuU5oDfffFMNDQ2aO3euPv/5z+vw4cNnrM3n8+ru7h5yAwBMfCPegJYsWaJNmzZp69at2rBhgw4dOqRPfepT6unpOW19S0uLqqurB2+NjY0jPSUAwBgUOevnFBt1dnZq9uzZevzxx3XnnXd+4P58Pq98Pj/4dXd3txobG/Xiy69q8uQpXj8jzcuwz7Px+jJsY/2F8jJsw9jF2PiR3Mp618Zj6GXYxkNcltFj41wsD9GplPUjuQ2Pb4Z5D/Se1Jc/c4O6urpUVVV1xrpRf3VATU2NLr/8ch04cOC09+dyOeVyudGeBgBgjBn19wGdPHlSBw8e1IwZM0b7RwEAxpERb0Bf/OIX1draqt/97nf62c9+ps985jNKp9P67Gc/O9I/CgAwjo34n+Deeustffazn9WJEyc0bdo0ffKTn9SuXbs0bdo00zjtHUdVUVHhVXvRxVO9x81OmmSah1Jp/1Jj1Etk+Zu3NRok5T+2M0WxDEPKcJgZ96GJdWjD8zRJZPu7fuIKtnr/w1CxNXLI8GtopswwEUmWs61Ysu3DOC5515qf/zP+h5Lh4CqanjGyzSWyPotqOPdjQ61vvNOIN6BnnnlmpIcEAExAZMEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIIY9Y9jGK4jx46r3DO37e3ufu9xs+V++XLvqag882dZvN9FVTW2sbP+H0MRJ/65V5Lts2wsuXGSFKWMmXeGfKrI+Lk6lpwsax5YmSH3LC7Yst0KA32m+ky5f6paLmP7eJO8IYNtoM82757uTu/ari7/WkkqFIretTNnzjSNXVNTY6rPGz4nKTF8fpkkJYbMSOeMmYSGsS0fBeUyfnVcAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAghizUTy/Ofh7ZXN+kSLpTLn3uFGZZ0bEHxVj/2iLy+bNM4191RXzvWvLMrbfFdIp/+2MImNGjTHuI2Ua3za2DGM7QySQJBUNcUa9fQOmsRXbIody5Vnv2v4+W2zTL/bt96793eHfmcaOY/+YrDj2j9Y5VR971/72twdMYy9a9HFTfd0l/lE/KWuUlSEqyxo3lTbMJZX41xbTfrVcAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCGLNZcN19RWVKfv0xkX8mVMmYlVQyRJP15dtMY/fm/XOyZs28xDR2TXWVd21Z2jS0ystteXqZjCX7ypYFZ8u+si1+psw/f62szHYq5fO23LNCwX+/vP7Gr01jt+74qXdtZIsx08VTJxnGtq2PMyz+H/7wjmns3bt/Zqr/yLxLvWsvm7/ANPakcsM+NI1sy0eMDPs7cn6PyVwBAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIIYs1lwpSRWlPjlCcWeuUOnxrXNw6X8d1HvgH+2myS9+duD3rUdHcdMY9dMmeJdW56xhcHNvKTeVD93XqN3bbrMmGZlKI9j2+KXZ/3XvmxyhWnsd9+2reex4/5ZZkd//3vT2LUX1XrXVlVXmsbO5Arete+++7ZpbFNynDFnrqu701S/f/9r3rX9A72msRtn+p8/VdXVprGnTJnsXZsynGupiCw4AMAYZm5AO3bs0E033aSGhgZFUaTnnntuyP3OOT344IOaMWOGJk2apGXLlunNN98cqfkCACYIcwPq7e3VokWLtH79+tPe/9hjj+k73/mOnnzySe3evVuTJ0/W8uXLNTAwcM6TBQBMHObngFauXKmVK1ee9j7nnJ544gl99atf1c033yxJ+v73v6+6ujo999xzuv32289ttgCACWNEnwM6dOiQ2tvbtWzZssHvVVdXa8mSJdq5c+dp/08+n1d3d/eQGwBg4hvRBtTe3i5JqqurG/L9urq6wfver6WlRdXV1YO3xkb/V3wAAMav4K+CW7dunbq6ugZvR44cCT0lAMB5MKINqL7+1PtDOjo6hny/o6Nj8L73y+VyqqqqGnIDAEx8I9qA5syZo/r6em3btm3we93d3dq9e7eamppG8kcBAMY586vgTp48qQMHDgx+fejQIe3bt0+1tbWaNWuW7r//fv3jP/6jLrvsMs2ZM0df+9rX1NDQoFtuuWUk5w0AGOfMDWjPnj369Kc/Pfj12rVrJUmrV6/Wpk2b9KUvfUm9vb26++671dnZqU9+8pPaunWrysvLjT/JP8JDkX9GRDpti52xXCOmUrYLyiT2jxDqerfPNHa++w/etRWZjGnsiyfnTPWlPv+ol5IxiccSxZMYo3g6+/33eWQ8leLEcHxLKhT953LZ5XNMY3/kUv/6VNq2QJ1dR71r3333uGnsOC5515ZK/ufacDjDuXzwzTbT2G8bYrimTptmGnuaoT5y/ms/0O8XS2ZuQNdff72cO3OuUhRFeuSRR/TII49YhwYAXECCvwoOAHBhogEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCMEfxnC8p9Sklz6ynyL+Pusi4yYaxFdtyshL559KlE1uOWVnKfzvnXDLTNPalsy4x1buCf+5Zb58t8y4x7JdC0Za/1u+ZZyVJBWPOXKFkq4/S/uuZLbNl+3V1n/SuLRTyprGzWf9jvK5uumnsY8f8M9Ik4/42VZ+KIPOeSWw7Drs6T3jX9vS8axr7rcOH/IuTM0ewvV/R85znCggAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEMSYjeIpDPxBSewXKeIswRmWaB1JSvnXp40xP4mh3tmSRJSqqvGuvaim2jR278leU32+UPSu7csPmMYuJLF37UDJM9rpj3oH/OcSF21j9/fbIm1iQ7SSS9viWHpO9njXFgu29Skvz3rX5vP+0UeSVCwaTgrj2kfyP64kKUr5x9QkxpO5FPvPxTn/eUhS3hAhZIknKnqe81wBAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIIYs1lwxXwsl/j1R0v+UTbjn00lSYnzz5BKIlt+VEn+GWkpUxKT1Nvjn+9VU11lGru2+iJT/fETJ7xr0575f+/JRP7r2Z/Ycsxcmf9xlTHmAGbS5ab6E30F79pjx21ZcKWSfy5dXLRl2L3zrn9uYBL7b6MkJYbsOJfvNo2dSdnO5TLDYZvYTmWVDDl2mTLbcZg21BcK/mtf8sxG5AoIABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABDEmI3iuWzu1crm/OJKLFE8UWTLwUiSxLs2ZUuRUTpjiXqxzbsy5x9R09hQZxq71hjdU1Wd867tG7DF5STO/3eo/oJ/9JEkRSn/0yOd2KJbKiZXmuoPtvvH67yy8+emsfOGeJ3EGDmktP/5o8Q/ckaSirH/+eNsy6PIGH0Vl/znkiqz/d6fzkzyri3L2h6E4th/fU72+8cqEcUDABjTaEAAgCDMDWjHjh266aab1NDQoCiK9Nxzzw25/4477lAURUNuK1asGKn5AgAmCHMD6u3t1aJFi7R+/foz1qxYsULHjh0bvD399NPnNEkAwMRjfhHCypUrtXLlyg+tyeVyqq+vH/akAAAT36g8B7R9+3ZNnz5d8+fP17333qsTH/KBZPl8Xt3d3UNuAICJb8Qb0IoVK/T9739f27Zt0z/90z+ptbVVK1euVByf/nWQLS0tqq6uHrw1NjaO9JQAAGPQiL8P6Pbbbx/891VXXaWFCxdq3rx52r59u5YuXfqB+nXr1mnt2rWDX3d3d9OEAOACMOovw547d66mTp2qAwcOnPb+XC6nqqqqITcAwMQ36g3orbfe0okTJzRjxozR/lEAgHHE/Ce4kydPDrmaOXTokPbt26fa2lrV1tbq4Ycf1qpVq1RfX6+DBw/qS1/6ki699FItX758RCcOABjfzA1oz549+vSnPz349XvP36xevVobNmzQ/v379a//+q/q7OxUQ0ODbrzxRv3DP/yDcjn/PDBJmlxZq1y5XwaSJd/Nkht3qt6/Nlth28bsFP/cppwxzGrW9Brv2sZLbC+ZL/b3mOor/CL9JElJybadhbx/jtlkW7yXXMk/Oy4yZsFVl1eb6ieXG3LpjH/XSJdZsvpsr1Id6Ov3L05sWX3Tp/lnGFZWzDSNnUnZHicyubR3bdb4WGjKrzQ+vpVK/vl7ff3+OY2FfF57tv6/s9aZG9D111//oQ/iL730knVIAMAFiCw4AEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQI/55QCNloNSjpOiXDWWM+DKx5DAlRVsOU1Tyz4TKZW2/K8xouMS7dlrddNPYAyf9M+wkqcr5f8RGFNm208WG1U9sR0qp6J/vljYehH0l27Hy7m+OeNcWjWMXSol37Yk/dJnGjpz/2DXVlaaxi4a17zzpn2MmSZONuY6Ty/3rp1TUmMYuL/cPU8xms6axLUqx/1rm+/0yALkCAgAEQQMCAARBAwIABEEDAgAEQQMCAARBAwIABEEDAgAEQQMCAARBAwIABEEDAgAEMWajeFJlUsqW+DIqDEk8KsvY8ljShtiZbMa2M1IZ/0iO37/9jmnsgd5OU70MyTAnT/bZxo78D+HE2danu/ukd23KGAjV3V8w1R84csy7tqS0aWyl/I/D8kn+sTCSVFPlH8M0dWqtaey+fv/1SUq2/e0ytiieJDXJu7YU2caODfVFGR8nLFFjKf8oHt9aroAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQYzZLDgp98fbyIos4W6SUoacrHRky2FKJ7F3bb6/ZBp73/7XvWv3FntNY3e9e8JUH5X893kpNgTHSeov+e9DS60kdff559L19tgy7Aby/rlakjSQ8j8XyqsuMo2dyfqPPW3aNNPYk8r9xy4UbeujlP/DV7bCPxtRkqIyW55ebAiuHCjajvGSK3rXpgu2sdNpyzWI/9iFvN/jFVdAAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgxmwUT5ykFCe2OAwfUWTruU7+MTJFW1qOUin/6JFSYotusaR9HD/+jmnsQ789YJtLr39MjbNtpnqL/jElJcNaSlIx8d+J1rV3ssU2ZSuqvGurUrbYmeqqSu/aKblJprGTUsG7tr8wYBpbZf7ncmSIypEkGddzIPbfzmLJGJeT8j9uU6ZoHcmSTGY5ewoDfmvJFRAAIAhTA2ppadHVV1+tyspKTZ8+Xbfccova2tqG1AwMDKi5uVkXX3yxpkyZolWrVqmjo2NEJw0AGP9MDai1tVXNzc3atWuXXn75ZRWLRd14443q7f2fNOUHHnhAL7zwgp599lm1trbq6NGjuvXWW0d84gCA8c30HNDWrVuHfL1p0yZNnz5de/fu1XXXXaeuri499dRT2rx5s2644QZJ0saNG/XRj35Uu3bt0ic+8YmRmzkAYFw7p+eAurq6JEm1tbWSpL1796pYLGrZsmWDNQsWLNCsWbO0c+fO046Rz+fV3d095AYAmPiG3YCSJNH999+va6+9VldeeaUkqb29XdlsVjU1NUNq6+rq1N7eftpxWlpaVF1dPXhrbGwc7pQAAOPIsBtQc3Oz3njjDT3zzDPnNIF169apq6tr8HbkyJFzGg8AMD4M631Aa9as0YsvvqgdO3Zo5syZg9+vr69XoVBQZ2fnkKugjo4O1dfXn3asXC6nXG7kP3obADC2ma6AnHNas2aNtmzZoldffVVz5swZcv/ixYuVyWS0bdu2we+1tbXp8OHDampqGpkZAwAmBNMVUHNzszZv3qznn39elZWVg8/rVFdXa9KkSaqurtadd96ptWvXqra2VlVVVbrvvvvU1NTEK+AAAEOYGtCGDRskSddff/2Q72/cuFF33HGHJOlb3/qWUqmUVq1apXw+r+XLl+t73/veiEwWADBxmBqQc2fPMCovL9f69eu1fv36YU9KkmI5xfIMBjNFK9lymCJDNpmLbdl1xYJ/upIxwk5p/5g5qdw/Z0ySahtmm+q7T/gnYXS9+65p7GLef4Hi2Lb2xaL/TiwYM+ysL/9JG3LSir0nTWMnGf/suL4+24b29Z7wrp1UPdk0drZiindtebktHy9XZsyOs+TvpaxPvRuO8cQ/G1GSIsMDXGLIRnTO79whCw4AEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEMSwPo7hfIgTp9g3+sEjImhQ5B9/I0mWaqeSaWwZoi2ilHHehhiZxBhPlJtUYas3RKbEnbZPxM2X/OdeKtpiZHp6er1r08bolmy5LbYpKea9awsDfaax3z3hvw/fefu4aexi0T8WaPblc85e9L9kpvgfh1HK9rt2ktiOlZTh/EylbWsfGa4TopTtXE6X+c87U+bfLgoZv23kCggAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQxJjNgivEiVTyzGOyZMGZ0t1sGWypxD9/TZKc/OuNUVZS5D+2c7Z5F0u2zLuy7CTv2uykStvYA/6ZXS6yzTtb7l+bNq6P9VjJ9/vnu/X39ZvGjpPRyQOTpFTav77XOO8qw+/P1qw+xbZMNctDUBLbcuac8z9uE0OtJEUp/1y6tOGh07eWKyAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBBjNoqnWCpJac9YCUMMhiVaR5JSzr9HG4dWFPn/h8TZ4juSpGgY2xghZKwvM8SgTJ402TR2qeC/X/qjAdPYxbxh7J5O09i9PV2m+pIh6yVbbtuHNbVTvWvr6meYxu7r7fGuPdmXN41dNETaFI3ROmXO+jjhX5vEtrgcRf6DZzK2h/SyMv8ontgwb99aroAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQdCAAABB0IAAAEHQgAAAQYzZLLh8MVaS8s0c889KsuSvSZIzZHAZIpskSWnLXCJbFpzkX++cLZsq7R8fJUmKSv7jZwzzlqSut49717799h9MY/f3G7LjSgXT2CnjdmayWe/atPHXymzO/2GgaNzO3v5+/+Kcf2agJJUMu3CgYDvGrVlwkWE9I/P6+O+XVMp2ctoeDw0T99xIroAAAEGYGlBLS4uuvvpqVVZWavr06brlllvU1tY2pOb6669XFEVDbvfcc8+IThoAMP6ZGlBra6uam5u1a9cuvfzyyyoWi7rxxhvV29s7pO6uu+7SsWPHBm+PPfbYiE4aADD+mZ4D2rp165CvN23apOnTp2vv3r267rrrBr9fUVGh+vr6kZkhAGBCOqfngLq6Tn2oVm1t7ZDv/+AHP9DUqVN15ZVXat26derr6zvjGPl8Xt3d3UNuAICJb9ivgkuSRPfff7+uvfZaXXnllYPf/9znPqfZs2eroaFB+/fv15e//GW1tbXpRz/60WnHaWlp0cMPPzzcaQAAxqlhN6Dm5ma98cYb+ulPfzrk+3fffffgv6+66irNmDFDS5cu1cGDBzVv3rwPjLNu3TqtXbt28Ovu7m41NjYOd1oAgHFiWA1ozZo1evHFF7Vjxw7NnDnzQ2uXLFkiSTpw4MBpG1Aul1MulxvONAAA45ipATnndN9992nLli3avn275syZc9b/s2/fPknSjBkzhjVBAMDEZGpAzc3N2rx5s55//nlVVlaqvb1dklRdXa1Jkybp4MGD2rx5s/7iL/5CF198sfbv368HHnhA1113nRYuXDgqGwAAGJ9MDWjDhg2STr3Z9H/buHGj7rjjDmWzWb3yyit64okn1Nvbq8bGRq1atUpf/epXR2zCAICJwfwnuA/T2Nio1tbWc5rQe0pJoijxzFcy5LVZJaYsONs8MoYYJmfIu5OkKPLN0ZMsuXGSVCoWTfWZYt67tr+70zT2u8ePedeW+m05ZmnDbomcNavPeMz6ngsyZgxKKsX+69lz0vY2ibzhWKmYUmEaW4btLBn2nyTJmAVneT9L2hgGZ5lJqWQ576U48V+fyDCTgmf2HllwAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAghv15QKMtiUtKSn4xEWeLCBpaa5uHJdUkMkZsxIZoi8gYl2Opj+QXm/Gegf6TpvpeQ7zOyU7/WklKGeaeThljSgwxMs4Y9WI9VlKGUzWVssXIFPL+UUmlvC2GKV3m/1ErmYztY1nyA4a5OOO5aYwzKkunvWsT41xShs1MJ8YHOOd/TkQp/20s5v1ir7gCAgAEQQMCAARBAwIABEEDAgAEQQMCAARBAwIABEEDAgAEQQMCAARBAwIABEEDAgAEQQMCAAQxZrPgFJek2C97yJQFZ8zssoTBJemMaegkZcj3ki3jqSwyZMElfrlN73GFXlN9fqDfu/Zkn23sYuwflJUYM++cITsuiowZXEZRyjC+LcbMlI9ozlIs8z/GI+Pvw7EhC65oPO0TQ+6ZJCVZ/x+QNmbByXBspWTLO3SGLLhcLutdG3uel1wBAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCoAEBAIKgAQEAgqABAQCCGLNRPC5JlHjG5rjEEMVjjLSx8J3vIGeot0SxSIpj/9iZOO8flSNJ/ca4nH5DFM9APm8aO078o0TMa2+IQHGWtZQURbbf/SJDJJSlVpIsu8U6tmU7LZFaki1Wy5VsETWJ8ZHRMnxsjMuRIS4nJdtx6BL/x4lsxj9qzPcxmSsgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBBjNguulEi+sUaWDClr3pQl+sqaB+bkn8OklC0/aiD2z1Qr9Nqy3Qb6bdlxAwMD/nMpFExjW/L37GtvWHxjtluZIVdLkjJZ/3prXlti2S/GsVOp0fsd17Kepm089R9sc4kN56dxbMX++zwd2R6D0oEvQbgCAgAEYWpAGzZs0MKFC1VVVaWqqio1NTXpxz/+8eD9AwMDam5u1sUXX6wpU6Zo1apV6ujoGPFJAwDGP1MDmjlzph599FHt3btXe/bs0Q033KCbb75Zv/zlLyVJDzzwgF544QU9++yzam1t1dGjR3XrrbeOysQBAOOb6Tmgm266acjX3/jGN7Rhwwbt2rVLM2fO1FNPPaXNmzfrhhtukCRt3LhRH/3oR7Vr1y594hOfGLlZAwDGvWE/BxTHsZ555hn19vaqqalJe/fuVbFY1LJlywZrFixYoFmzZmnnzp1nHCefz6u7u3vIDQAw8Zkb0Ouvv64pU6Yol8vpnnvu0ZYtW3TFFVeovb1d2WxWNTU1Q+rr6urU3t5+xvFaWlpUXV09eGtsbDRvBABg/DE3oPnz52vfvn3avXu37r33Xq1evVq/+tWvhj2BdevWqaura/B25MiRYY8FABg/zO8DymazuvTSSyVJixcv1s9//nN9+9vf1m233aZCoaDOzs4hV0EdHR2qr68/43i5XE65XM4+cwDAuHbO7wNKkkT5fF6LFy9WJpPRtm3bBu9ra2vT4cOH1dTUdK4/BgAwwZiugNatW6eVK1dq1qxZ6unp0ebNm7V9+3a99NJLqq6u1p133qm1a9eqtrZWVVVVuu+++9TU1MQr4AAAH2BqQMePH9df/uVf6tixY6qurtbChQv10ksv6c///M8lSd/61reUSqW0atUq5fN5LV++XN/73veGNbF8sajYN95kFCM5UoboEeebHfRHsSFGpqiiaWxXOOldW+j3r5WkvCFaR5IG+sdGFI+VJdImk7H9Nbu8vNxU79L+4ztZY2f892GUtg0tw1ysa1ks+p8TcckQeyWZI4eiMv8/Jln3oWFopYyPQbmM/2T6+/q8a4t5vygw01nz1FNPfej95eXlWr9+vdavX28ZFgBwASILDgAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEAQNCAAQBA0IABAEDQgAEIQ5DXu0uT9G5ZSKhkiWMRPFY+vnligeZ43iMey/2BBpItljTZLYvz6JY9PYLrHVj5bEmn5j3U7570NnzHpxieG49Y3H+qOkZIjLsZzzkuKU4dw0RuuYo3gS/3pznJEpisd2IKad/+DFlH9tqXAqised5fE2cmerOM/eeustPpQOACaAI0eOaObMmWe8f8w1oCRJdPToUVVWVg4Jg+zu7lZjY6OOHDmiqqqqgDMcXWznxHEhbKPEdk40I7Gdzjn19PSooaFBqQ+5chpzf4JLpVIf2jGrqqom9OK/h+2cOC6EbZTYzonmXLezurr6rDW8CAEAEAQNCAAQxLhpQLlcTg899JByuVzoqYwqtnPiuBC2UWI7J5rzuZ1j7kUIAIALw7i5AgIATCw0IABAEDQgAEAQNCAAQBDjpgGtX79eH/nIR1ReXq4lS5bov/7rv0JPaUR9/etfVxRFQ24LFiwIPa1zsmPHDt10001qaGhQFEV67rnnhtzvnNODDz6oGTNmaNKkSVq2bJnefPPNMJM9B2fbzjvuuOMDa7tixYowkx2mlpYWXX311aqsrNT06dN1yy23qK2tbUjNwMCAmpubdfHFF2vKlClatWqVOjo6As14eHy28/rrr//Aet5zzz2BZjw8GzZs0MKFCwffbNrU1KQf//jHg/efr7UcFw3ohz/8odauXauHHnpIv/jFL7Ro0SItX75cx48fDz21EfWxj31Mx44dG7z99Kc/DT2lc9Lb26tFixZp/fr1p73/scce03e+8x09+eST2r17tyZPnqzly5drYGDgPM/03JxtOyVpxYoVQ9b26aefPo8zPHetra1qbm7Wrl279PLLL6tYLOrGG29Ub2/vYM0DDzygF154Qc8++6xaW1t19OhR3XrrrQFnbeeznZJ01113DVnPxx57LNCMh2fmzJl69NFHtXfvXu3Zs0c33HCDbr75Zv3yl7+UdB7X0o0D11xzjWtubh78Oo5j19DQ4FpaWgLOamQ99NBDbtGiRaGnMWokuS1btgx+nSSJq6+vd9/85jcHv9fZ2elyuZx7+umnA8xwZLx/O51zbvXq1e7mm28OMp/Rcvz4cSfJtba2OudOrV0mk3HPPvvsYM2vf/1rJ8nt3Lkz1DTP2fu30znn/uzP/sz9zd/8TbhJjZKLLrrI/fM///N5XcsxfwVUKBS0d+9eLVu2bPB7qVRKy5Yt086dOwPObOS9+eabamho0Ny5c/X5z39ehw8fDj2lUXPo0CG1t7cPWdfq6motWbJkwq2rJG3fvl3Tp0/X/Pnzde+99+rEiROhp3ROurq6JEm1tbWSpL1796pYLA5ZzwULFmjWrFnjej3fv53v+cEPfqCpU6fqyiuv1Lp169TX1xdieiMijmM988wz6u3tVVNT03ldyzEXRvp+77zzjuI4Vl1d3ZDv19XV6Te/+U2gWY28JUuWaNOmTZo/f76OHTumhx9+WJ/61Kf0xhtvqLKyMvT0Rlx7e7sknXZd37tvolixYoVuvfVWzZkzRwcPHtTf//3fa+XKldq5c6fSaeuHw4SXJInuv/9+XXvttbryyislnVrPbDarmpqaIbXjeT1Pt52S9LnPfU6zZ89WQ0OD9u/fry9/+ctqa2vTj370o4CztXv99dfV1NSkgYEBTZkyRVu2bNEVV1yhffv2nbe1HPMN6EKxcuXKwX8vXLhQS5Ys0ezZs/Vv//ZvuvPOOwPODOfq9ttvH/z3VVddpYULF2revHnavn27li5dGnBmw9Pc3Kw33nhj3D9HeTZn2s6777578N9XXXWVZsyYoaVLl+rgwYOaN2/e+Z7msM2fP1/79u1TV1eX/v3f/12rV69Wa2vreZ3DmP8T3NSpU5VOpz/wCoyOjg7V19cHmtXoq6mp0eWXX64DBw6EnsqoeG/tLrR1laS5c+dq6tSp43Jt16xZoxdffFE/+clPhnxsSn19vQqFgjo7O4fUj9f1PNN2ns6SJUskadytZzab1aWXXqrFixerpaVFixYt0re//e3zupZjvgFls1ktXrxY27ZtG/xekiTatm2bmpqaAs5sdJ08eVIHDx7UjBkzQk9lVMyZM0f19fVD1rW7u1u7d++e0OsqnfrU3xMnToyrtXXOac2aNdqyZYteffVVzZkzZ8j9ixcvViaTGbKebW1tOnz48Lhaz7Nt5+ns27dPksbVep5OkiTK5/Pndy1H9CUNo+SZZ55xuVzObdq0yf3qV79yd999t6upqXHt7e2hpzZi/vZv/9Zt377dHTp0yP3nf/6nW7ZsmZs6dao7fvx46KkNW09Pj3vttdfca6+95iS5xx9/3L322mvuv//7v51zzj366KOupqbGPf/8827//v3u5ptvdnPmzHH9/f2BZ27zYdvZ09PjvvjFL7qdO3e6Q4cOuVdeecX9yZ/8ibvsssvcwMBA6Kl7u/fee111dbXbvn27O3bs2OCtr69vsOaee+5xs2bNcq+++qrbs2ePa2pqck1NTQFnbXe27Txw4IB75JFH3J49e9yhQ4fc888/7+bOneuuu+66wDO3+cpXvuJaW1vdoUOH3P79+91XvvIVF0WR+4//+A/n3Plby3HRgJxz7rvf/a6bNWuWy2az7pprrnG7du0KPaURddttt7kZM2a4bDbrLrnkEnfbbbe5AwcOhJ7WOfnJT37iJH3gtnr1aufcqZdif+1rX3N1dXUul8u5pUuXura2trCTHoYP286+vj534403umnTprlMJuNmz57t7rrrrnH3y9Pptk+S27hx42BNf3+/++u//mt30UUXuYqKCveZz3zGHTt2LNykh+Fs23n48GF33XXXudraWpfL5dyll17q/u7v/s51dXWFnbjRX/3VX7nZs2e7bDbrpk2b5pYuXTrYfJw7f2vJxzEAAIIY888BAQAmJhoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIAgaEAAgCBoQACAIGhAAIIj/D+Cfbfrw0e++AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c54df2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs.train_data/' + cur_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cab1cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs.train_data/20230304-045301'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cbb2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8cbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.randint(10000, size=10):\n",
    "    img = train_x[i : i+1]\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image('Training sample {}'.format(i), img, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7b5357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/train_data --bind_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c723f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5604c2b",
   "metadata": {},
   "source": [
    "### LambdaCallback을 사용하여 Tensorboard에 Confusion Matrix 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f228a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \n",
    "    figure = plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    threshold = cm.max() /2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            color = 'white' if cm[i, j] > threshold else 'black'\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment='center', color=color)\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "logdir = 'log/fit/cm/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "test_images = test_x[:100]\n",
    "test_labels = np.argmax(test_y[:100], axis=1)\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    test_pred_raw = model.predict(test_images)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "    \n",
    "    classes = np.arange(10)\n",
    "    cm = confusion_matrix(test_labels, test_pred, labels = classes)\n",
    "    \n",
    "    figure = plot_confusion_matrix(cm, class_names= classes)\n",
    "    cm_image = plot_to_image(figure)\n",
    "    \n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image('Confusion Matrix', cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e37e2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end = log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3c686e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.3144 - accuracy: 0.1001 - val_loss: 2.3097 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.3318 - accuracy: 0.1004 - val_loss: 2.3293 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 2.3421 - accuracy: 0.0988 - val_loss: 2.3382 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 2.3384 - accuracy: 0.1010 - val_loss: 2.3116 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 2.3223 - accuracy: 0.0997 - val_loss: 2.3305 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2eed51730>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x,y=train_y,epochs = 5,batch_size = 32,\n",
    "          validation_data = (test_x, test_y),callbacks=[cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8ad0c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit/cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ea444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.8.15('ds_study':conda)",
   "language": "python",
   "name": "ds_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
