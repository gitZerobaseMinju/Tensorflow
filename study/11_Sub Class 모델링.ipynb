{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a75c107",
   "metadata": {},
   "source": [
    "# Sub Class 모델링\n",
    "\n",
    "모델이란 것은 Input을 Output으로 만들어주는 수식이다.\n",
    "\n",
    "해당 기능을 수행하는 두가지 클래스가 tf.keras.layers.Layer 와 tf.keras.layers.Mdel클래스이다.\n",
    "\n",
    "두가지 모두 **연산을 추상화** 하는 것으로 동일한 역할을 하지만, tf.keras.layers.Model 클래스의 경우 모델을 저장하는 기능과 fit 함수를 사용할 수 있다는 점에서 차이가 있다.\n",
    "\n",
    "- tf.keras.layers.Layer\n",
    "- tf.keras.layers.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d623b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6851c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7777)\n",
    "tf.random.set_seed(7777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f747c",
   "metadata": {},
   "source": [
    "### Linear Regression을 Layer로 만들어 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c809782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=1):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = tf.Variable(0.0)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b5ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7267365",
   "metadata": {},
   "source": [
    "#### 가상데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1274bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_true = np.array([3., 2., 4., 1.]).reshape(4,1)\n",
    "B_true = np.array([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e1f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.normal((500, 4))\n",
    "noise = tf.random.normal((500, 4))\n",
    "\n",
    "y = X @ W_true + B_true + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150b3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.03)\n",
    "\n",
    "linear_layer = LinearRegression(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52dd19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 loss : 34.02492904663086\n",
      "epoch : 10 loss : 9.377575874328613\n",
      "epoch : 20 loss : 3.130983352661133\n",
      "epoch : 30 loss : 1.5325844287872314\n",
      "epoch : 40 loss : 1.1196198463439941\n",
      "epoch : 50 loss : 1.0118862390518188\n",
      "epoch : 60 loss : 0.9835036993026733\n",
      "epoch : 70 loss : 0.9759520888328552\n",
      "epoch : 80 loss : 0.9739224910736084\n",
      "epoch : 90 loss : 0.9733714461326599\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = linear_layer(X)\n",
    "        loss = tf.reduce_mean(tf.square(y - y_hat))\n",
    "        \n",
    "    grads = tape.gradient(loss, linear_layer.trainable_weights)\n",
    "    opt.apply_gradients(zip(grads, linear_layer.trainable_weights))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch : {} loss : {}'.format(epoch, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d592ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db730237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "266b3767",
   "metadata": {},
   "source": [
    "### ResNet - Sub Class로 구현하기\n",
    "\n",
    "1. Residual Block - Layer\n",
    "2. ResNet - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b66592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba3c98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, filters=32, filter_match=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = Conv2D(filters, kernel_size=1, padding='same', activation='relu')\n",
    "        self.conv2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')\n",
    "        self.conv3 = Conv2D(filters, kernel_size=1, padding='same', activation='relu')\n",
    "        self.add = Add()\n",
    "        self.filters = filters\n",
    "        self.filter_match = filter_match\n",
    "        if self.filter_match:\n",
    "            self.conv_ext = Conv2D(filters, kernel_size=1, padding='same')\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        net1 = self.conv1(inputs)\n",
    "        net2 = self.conv2(net1)\n",
    "        net3 = self.conv3(net2)\n",
    "        if self.filter_match:\n",
    "            res = self.add([self.conv_ext(inputs), net3])\n",
    "        else:\n",
    "            res = self.add([inputs, net3])\n",
    "            \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f11a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(32, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.maxp1 = MaxPool2D()\n",
    "        self.block1 = ResidualBlock(64, True)\n",
    "        self.block2 = ResidualBlock(64)\n",
    "        self.maxp2 = MaxPool2D()\n",
    "        self.flat = Flatten()\n",
    "        self.dense = Dense(num_classes)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.maxp1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.maxp2(x)\n",
    "        x = self.flat(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49c7a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4683402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6a97389",
   "metadata": {},
   "source": [
    "#### 학습 시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b6ac34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \n",
    "    def __init__(self):\n",
    "        (self.train_x, self.train_y),(self.test_x, self.test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "        \n",
    "    def validate_pixel_scale(self, x):\n",
    "        return 255 >= x.max() and 0 <= x.min()\n",
    "    \n",
    "    def scale(self, x):\n",
    "        return (x / 255.0).astype(np.float32)\n",
    "    \n",
    "    def preprocess_dataset(self, dataset):\n",
    "        feature, target = dataset\n",
    "        \n",
    "        validated_x = np.array([x for x in feature if self.validate_pixel_scale(x)])\n",
    "        validated_y = np.array([y for x, y in zip(feature, target) if self.validate_pixel_scale(x)])\n",
    "        \n",
    "        # scale\n",
    "        scaled_x = np.array([self.scale(x) for x in validated_x])\n",
    "    \n",
    "        # label encoding\n",
    "        ohe_y = np.array([tf.keras.utils.to_categorical(y, num_classes=10) for y in validated_y])\n",
    "        \n",
    "        return scaled_x, np.squeeze(ohe_y, axis=1)\n",
    "    \n",
    "    def get_train_dataset(self):\n",
    "        return self.preprocess_dataset((self.train_x, self.train_y))\n",
    "    \n",
    "    def get_test_dataset(self):\n",
    "        return self.preprocess_dataset((self.test_x, self.test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c550d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "\n",
    "train_x, train_y = loader.get_train_dataset()\n",
    "\n",
    "test_x, test_y = loader.get_train_dataset()\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "245626a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03\n",
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fee5f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 50s 123ms/step - loss: 2.9105 - accuracy: 0.0847 - val_loss: 2.2871 - val_accuracy: 0.0663\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_x, train_y, epochs=1, batch_size=128, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fbbba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.8.15('ds_study':conda)",
   "language": "python",
   "name": "ds_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
